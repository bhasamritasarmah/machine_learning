# -*- coding: utf-8 -*-
"""univariate_linear_regression.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1UtKy8bE-NF3oA_HIL7Zx9r4mTrxbD4EM
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize
from sklearn.linear_model import LinearRegression

#generates a random matrix of size (m, n)
x = np.linspace(-4, 4, 100)
a = np.random.rand(1)
y_predict = a * (x/x)
noise = np.random.rand(1)
y_truth = np.sin(x) + noise
w = [a]
step = 0.0001

def loss(w) :
  mae = np.mean(np.abs(y_truth - y_predict))
  return mae

def grad(w) :
  for i in range (len(x)):
    y_predict = w
    Da = (-2/len(x)) * sum (y_truth - y_predict)
    w = w - step*Da
    return w

res = minimize(fun = loss, x0 = w, jac = grad, method = 'BFGS')

plt.xlabel("x-axis (in radians)")
plt.ylabel("y-axis (sin(x)) and (a)")
plt.scatter(x, y_truth)
plt.plot(x, y_predict, color = "red")

print ("Mean absolute error -", res.fun)

x = np.linspace(-4, 4, 100)
a = np.random.rand(1)
b = np.random.rand(1)
noise = np.random.rand(1)
y_predict = a * x + b
y_truth = np.sin(x) + noise
step = 0.0001
w = [a, b]

def loss(w) :
  mae = np.mean(np.abs(y_truth - y_predict))
  return mae

def grad(w) :
  for i in range (len(x)):
    a = w[0]
    b = w[1]
    y_predict = a * x + b
    Da = (-2/len(x)) * sum (x * (y_truth - y_predict))
    Db = (-2/len(x)) * sum (y_truth - y_predict)
    a = a - step*Da
    b = b - step*Db
    return w
    
res = minimize(fun = loss, x0 = w, jac = grad, method = 'BFGS')

plt.xlabel("x-axis (in radians)")
plt.ylabel("y-axis (sin(x)) and (a*x+b)")
plt.scatter(x, y_truth)
plt.plot(x, y_predict, color = "red")

mae = np.mean(np.abs(y_truth - y_predict))
print ("Mean absolute error: ", res.fun)

x = np.linspace(-4, 4, 100)
a = np.random.rand(1)
b = np.random.rand(1)
y_predict = a * x**2 + b
noise = np.random.rand(1)
y_truth = np.sin(x) + noise
step = 0.0001
w = [a, b]

def loss(w) :
  mae = np.mean(np.abs(y_truth - y_predict))
  return mae

def grad(w) :
  for i in range (len(x)):
    a = w[0]
    b = w[1]
    y_predict = a * x**2 + b
    Da = (-2/len(x)) * sum (x**2 * (y_truth - y_predict))
    Db = (-2/len(x)) * sum (y_truth - y_predict)
    a = a - step*Da
    b = b - step*Db
    return w
    
res = minimize(fun = loss, x0 = w, jac = grad, method = 'BFGS')

plt.xlabel("x-axis (in radians)")
plt.ylabel("y-axis (sin(x)) and (a*x^2+b)")
plt.scatter(x, y_truth)
plt.plot(x, y_predict, color = "red")
print ("Mean absolute error: ", res.fun)

x = np.linspace(-4, 4, 100)
a = np.random.rand(1)
b = np.random.rand(1)
y_predict = a * x**3 + b
noise = np.random.rand(1)
y_truth = np.sin(x) + noise
step = 0.0001
w = [a, b]

def loss(w) :
  mae = np.mean(np.abs(y_truth - y_predict))
  return mae

def grad(w) :
  for i in range (len(x)):
    a = w[0]
    b = w[1]
    y_predict = a * x**3 + b
    Da = (-2/len(x)) * sum (x**3 * (y_truth - y_predict))
    Db = (-2/len(x)) * sum (y_truth - y_predict)
    a = a - step*Da
    b = b - step*Db
    return w
    
res = minimize(fun = loss, x0 = w, jac = grad, method = 'BFGS')

plt.xlabel("x-axis (in radians)")
plt.ylabel("y-axis (sin(x)) and (a*x^3+b)")
plt.scatter(x, y_truth)
plt.plot(x, y_predict, color = "red")
print ("Mean absolute error: ", res.fun)

x = np.linspace(-2, 2, 100)
a = np.random.rand(1)
b = np.random.rand(1)
y_predict = a * x**4 + b
noise = np.random.rand(1)
y_truth = np.sin(x) + noise
step = 0.0001
w = [a, b]

def loss(w) :
  mae = np.mean(np.abs(y_truth - y_predict))
  return mae

def grad(w) :
  for i in range (len(x)):
    a = w[0]
    b = w[1]
    y_predict = a * x**4 + b
    Da = (-2/len(x)) * sum (x**4 * (y_truth - y_predict))
    Db = (-2/len(x)) * sum (y_truth - y_predict)
    a = a - step*Da
    b = b - step*Db
    return w
    
res = minimize(fun = loss, x0 = w, jac = grad, method = 'BFGS')

plt.xlabel("x-axis (in radians)")
plt.ylabel("y-axis (sin(x)) and (a*x^4+b)")
plt.scatter(x, y_truth)
plt.plot(x, y_predict, color = "red")
print ("Mean absolute error: ", res.fun)

x = np.linspace(-2, 2, 100)
a = np.random.rand(1)
b = np.random.rand(1)
y_predict = a * x**5 + b
noise = np.random.rand(1)
y_truth = np.sin(x) + noise
step = 0.0001
w = [a, b]

def loss(w) :
  mae = np.mean(np.abs(y_truth - y_predict))
  return mae

def grad(w) :
  for i in range (len(x)):
    a = w[0]
    b = w[1]
    y_predict = a * x**5 + b
    Da = (-2/len(x)) * sum (x**5 * (y_truth - y_predict))
    Db = (-2/len(x)) * sum (y_truth - y_predict)
    a = a - step*Da
    b = b - step*Db
    return w
    
res = minimize(fun = loss, x0 = w, jac = grad, method = 'BFGS')


plt.xlabel("x-axis (in radians)")
plt.ylabel("y-axis (sin(x)) and (a*x^5+b)")
plt.scatter(x, y_truth)
plt.plot(x, y_predict, color = "red")
print ("Mean absolute error: ", res.fun)

x = np.linspace(-2, 2, 100)
a = np.random.rand(1)
b = np.random.rand(1)
y_predict = a * x**6 + b
noise = np.random.rand(1)
y_truth = np.sin(x) + noise
step = 0.0001
w = [a, b]

def loss(w) :
  mae = np.mean(np.abs(y_truth - y_predict))
  return mae

def grad(w) :
  for i in range (len(x)):
    a = w[0]
    b = w[1]
    y_predict = a * x**6 + b
    Da = (-2/len(x)) * sum (x**6 * (y_truth - y_predict))
    Db = (-2/len(x)) * sum (y_truth - y_predict)
    a = a - step*Da
    b = b - step*Db
    return w
    
res = minimize(fun = loss, x0 = w, jac = grad, method = 'BFGS')


plt.xlabel("x-axis (in radians)")
plt.ylabel("y-axis (sin(x)) and (a*x^6+b)")
plt.scatter(x, y_truth)
plt.plot(x, y_predict, color = "red")
print ("Mean absolute error: ", res.fun)

x = np.linspace(-2, 2, 100)
a = np.random.rand(1)
b = np.random.rand(1)
y_predict = a * x**7 + b
noise = np.random.rand(1)
y_truth = np.sin(x) + noise
step = 0.0001
w = [a, b]

def loss(w) :
  mae = np.mean(np.abs(y_truth - y_predict))
  return mae

def grad(w) :
  for i in range (len(x)):
    a = w[0]
    b = w[1]
    y_predict = a * x**7 + b
    Da = (-2/len(x)) * sum (x**7 * (y_truth - y_predict))
    Db = (-2/len(x)) * sum (y_truth - y_predict)
    a = a - step*Da
    b = b - step*Db
    return w
    
res = minimize(fun = loss, x0 = w, jac = grad, method = 'BFGS')

plt.xlabel("x-axis (in radians)")
plt.ylabel("y-axis (sin(x)) and (a*x^7+b)")
plt.scatter(x, y_truth)
plt.plot(x, y_predict, color = "red")
print ("Mean absolute error: ", res.fun)

x = np.linspace(-2, 2, 100)
a = np.random.rand(1)
b = np.random.rand(1)
y_predict = a * x**8 + b
noise = np.random.rand(1)
y_truth = np.sin(x) + noise
step = 0.0001
w = [a, b]

def loss(w) :
  mae = np.mean(np.abs(y_truth - y_predict))
  return mae

def grad(w) :
  for i in range (len(x)):
    a = w[0]
    b = w[1]
    y_predict = a * x**8 + b
    Da = (-2/len(x)) * sum (x**8 * (y_truth - y_predict))
    Db = (-2/len(x)) * sum (y_truth - y_predict)
    a = a - step*Da
    b = b - step*Db
    return w
    
res = minimize(fun = loss, x0 = w, jac = grad, method = 'BFGS')

plt.xlabel("x-axis (in radians)")
plt.ylabel("y-axis (sin(x)) and (a*x^8+b)")
plt.scatter(x, y_truth)
plt.plot(x, y_predict, color = "red")
print ("Mean absolute error: ", res.fun)

x = np.linspace(-1, 1, 100)
a = np.random.rand(1)
b = np.random.rand(1)
y_predict = a * x**9 + b
noise = np.random.rand(1)
y_truth = np.sin(x) + noise
step = 0.0001
w = [a, b]

def loss(w) :
  mae = np.mean(np.abs(y_truth - y_predict))
  return mae

def grad(w) :
  for i in range (len(x)):
    a = w[0]
    b = w[1]
    y_predict = a * x**9 + b
    Da = (-2/len(x)) * sum (x**9 * (y_truth - y_predict))
    Db = (-2/len(x)) * sum (y_truth - y_predict)
    a = a - step*Da
    b = b - step*Db
    return w
    
res = minimize(fun = loss, x0 = w, jac = grad, method = 'BFGS')

plt.xlabel("x-axis (in radians)")
plt.ylabel("y-axis (sin(x)) and (a*x^9+b)")
plt.scatter(x, y_truth)
plt.plot(x, y_predict, color = "red")
print ("Mean absolute error: ", res.fun)

x = np.linspace(-1, 1, 100)
a = np.random.rand(1)
b = np.random.rand(1)
y_predict = a * x**10 + b
noise = np.random.rand(1)
y_truth = np.sin(x) + noise
step = 0.0001
w = [a, b]

def loss(w) :
  mae = np.mean(np.abs(y_truth - y_predict))
  return mae

def grad(w) :
  for i in range (len(x)):
    a = w[0]
    b = w[1]
    y_predict = a * x**10 + b
    Da = (-2/len(x)) * sum (x**10 * (y_truth - y_predict))
    Db = (-2/len(x)) * sum (y_truth - y_predict)
    a = a - step*Da
    b = b - step*Db
    return w
    
res = minimize(fun = loss, x0 = w, jac = grad, method = 'BFGS')


plt.xlabel("x-axis (in radians)")
plt.ylabel("y-axis (sin(x)) and (a*x^10+b)")
plt.scatter(x, y_truth)
plt.plot(x, y_predict, color = "red")
print ("Mean absolute error: ", res.fun)
